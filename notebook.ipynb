{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e12d5a-a2e7-46fc-81a9-3086033e972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 12:35:18.886561: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-24 12:35:18.886633: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.applications.resnet import ResNet50\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    (trainX, y_train), (testX, y_test) = cifar10.load_data()\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "    return trainX, y_train, testX, y_test\n",
    "\n",
    "\n",
    "def preprocess_data(train_data, test_data):\n",
    "    train_normalize = train_data.astype('float32')\n",
    "    test_normalize = test_data.astype('float32')\n",
    "    train_normalize = train_normalize / 255.0\n",
    "    test_normalize = test_normalize / 255.0\n",
    "    return train_normalize, test_normalize\n",
    "\n",
    "\n",
    "def get_base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    optimizer_ = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer_, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], color='red', label='Train')\n",
    "    pyplot.plot(history.history['val_loss'], color='green', label='Test')\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='red', label='Train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='green', label='Test')\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "def transfer_learning_model():\n",
    "    base_model_2 = ResNet50(include_top=False, weights='imagenet', input_shape=(32, 32, 3), classes=10)\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(base_model_2)\n",
    "    model_2.add(Flatten())\n",
    "\n",
    "    model_2.add(Dense(4000, activation=('relu'), input_dim=512))\n",
    "    model_2.add(Dense(2000, activation=('relu')))\n",
    "    model_2.add(Dropout(.4))\n",
    "    model_2.add(Dense(1000, activation=('relu')))\n",
    "    model_2.add(Dropout(.3))\n",
    "    model_2.add(Dense(500, activation=('relu')))\n",
    "    model_2.add(Dropout(.2))\n",
    "    model_2.add(Dense(10, activation=('softmax')))\n",
    "    optimizer_ = tf.keras.optimizers.SGD()\n",
    "    model_2.compile(optimizer=optimizer_, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_2\n",
    "\n",
    "\n",
    "def run_task1():\n",
    "    X_train, y_train, X_test, y_test = get_dataset()\n",
    "    X_train, X_test = preprocess_data(X_train, X_test)\n",
    "\n",
    "    model = get_base_model()\n",
    "    manual_datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "    train_dataset = manual_datagen.flow(X_train, y_train, batch_size=64)\n",
    "    steps = int(X_train.shape[0] / 64)\n",
    "\n",
    "    history = model.fit(train_dataset, steps_per_epoch=steps, epochs=2, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Accuracy is {round(float(acc)*100, 3)}')\n",
    "    plot_history(history)\n",
    "\n",
    "    print('Starting ResNet 50 ')\n",
    "    model_2 = transfer_learning_model()\n",
    "    history = model_2.fit(train_dataset, steps_per_epoch=steps, epochs=2, validation_data=(X_test, y_test), verbose=1)\n",
    "    print(f'Accuracy is {round(float(acc)*100, 3)}')\n",
    "    plot_history(history)\n",
    "\n",
    "run_task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda0a02b-0b99-4d22-9627-ab2ba4b716c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Random Forest Classifier ...\n",
      "Completed!\n",
      "Training Accuracy Score 0.9896864256693405\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def processing_string(row, col):\n",
    "    word = row[col]\n",
    "    word = str(word).lower()\n",
    "    text_p = \"\".join([char for char in word if char not in string.punctuation])\n",
    "    filtered_words = [word for word in [text_p] if word not in stop_words]\n",
    "    stemmed = [porter.stem(word) for word in filtered_words]\n",
    "    if isinstance(stemmed, list):\n",
    "        row[col] = ''.join(stemmed)\n",
    "    else:\n",
    "        row[col] = stemmed\n",
    "    return row\n",
    "\n",
    "\n",
    "df = pd.read_csv('agr_en_train.csv', header=None)\n",
    "df.columns = ['sent1', 'sent2', 'label']\n",
    "\n",
    "df = df.apply(lambda x: processing_string(x, 'sent2'), axis=1)\n",
    "df = df.drop('sent1', axis=1)\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "yy = tfidf.fit_transform(df['sent2'])\n",
    "\n",
    "df_processd = pd.DataFrame(yy.toarray(), columns=tfidf.get_feature_names())\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_processd, df['label'], test_size=0.2)\n",
    "\n",
    "def build_randomforest_model(X_train, y_train, X_test, y_test):\n",
    "    print(\"Started Random Forest Classifier ...\")\n",
    "    model = RandomForestClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Completed!\")\n",
    "    print('Training Accuracy Score', model.score(X_train, y_train))\n",
    "    print('*' * 40)\n",
    "    return model\n",
    "\n",
    "random_forest = build_randomforest_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eaf5ce-0b49-4ebc-aa3c-16166d89bd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
